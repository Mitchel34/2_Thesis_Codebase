# Transformer Residual-Correction Run Plan (2010–2020)

This note replaces the previous 2010–2022 baseline and documents the refactored experiment plan that keeps every modeling artifact within the NWM v2.1 retrospective (2010–2020). All three core study sites—Watauga (03479000), Au Sable (04137500), and Green River (09234500)—share the same temporal splits:

- **Train**: 2010-01-01 → 2018-12-31
- **Validation**: 2019-01-01 → 2019-12-31
- **Test**: 2020-01-01 → 2020-12-31

Because the NWM v3 archive begins on 2021-01-01, this window is fully covered by v2.1 with no cross-version stitches.

> **Local-only reminder.** Logs, raw downloads, checkpoints, and evaluation bundles should be copied into `local_only/` after each run (`scripts/setup_local_storage.sh` bootstraps the directory tree).

## Data Acquisition Summary

- **NWM v2.1 retrospective** (`data_acquisition_scripts/nwm.py --mode retrospective`): hourly CSVs saved to `data/raw/nwm_v2/retrospective/` per site. Each pull includes a log such as `logs/nwm_v2_03479000.log`.
- **USGS observations** (`data_acquisition_scripts/usgs.py`): hourly‐aligned discharges for each USGS gage under `data/raw/usgs/`.
- **ERA5 forcings** (`data_acquisition_scripts/era5.py`): hourly meteorology written to `data/raw/era5/<site>/`.
- NLCD land-use metrics were removed from the pipeline; no static rasters are required.

## Dataset Preparation

The dataset builder now enforces `nwm_version=v2` by default:

```bash
python modeling/build_training_dataset.py \
  --raw-dir data/raw \
  --out-dir data/clean/modeling \
  --start 2010-01-01 \
  --end 2020-12-31 \
  --sites 03479000 04137500 09234500 \
  --nwm-version v2
```

Outputs:
- `data/clean/modeling/hourly_training_all_sites_20100101_20201231.parquet`
- Site-specific parquet and CSV slices (named `<site>_20100101_20201231`) generated by `scripts/run_site_pipeline.py`.

Each record includes:
- `nwm_cms`, `usgs_cms`, ERA5 features (dynamic)
- `y_residual_cms`, `y_corrected_cms`
- Metadata columns: `site_id`, `site_name`, `state`, `region`, `biome`, `regulation_status`

## Training Configuration

Both transformer and LSTM baselines pull splits from `configs/train_val_test.json` (2010–2018 train, 2019 val, 2020 test). The `Makefile` wires these values through to `modeling/train_quick_transformer_torch.py`:

```bash
make train_full \
  OUTPUT_PREFIX=watauga_v2 \
  DATA_PATH=data/clean/modeling/hourly_training_03479000_20100101_20201231.parquet
```

Key options baked into `make train_full`:
- `--train-start 2010-01-01 --train-end 2018-12-31`
- `--val-start 2019-01-01 --val-end 2019-12-31`
- Test window defaults to the remaining timestamps (2020).
- Static features are optional; for this refactor the models only ingest the regulation flag derived from `regulation_status`.

## Multi-Site Execution

Use the new helper to run all three sites sequentially:

```bash
python scripts/run_multi_site_pipeline.py
```

This command:
1. Builds the per-site parquet (NWM v2, 2010–2020) if missing.
2. Trains the Hydra transformer via `make train_full` and triggers Optuna HPO when the baseline improvement is below 5%.
3. Generates evaluation CSV/JSON artifacts under `data/clean/modeling/`.

Override `--sites` to focus on a subset, or pass `--skip-hpo`/`--skip-plots` to shorten the loop.

## Evaluation Checklist (per site)

1. Inspect `*_metrics.json` for RMSE, NSE, KGE, and PBIAS deltas versus raw NWM on the 2020 test year.
2. Verify that the 2010–2018 training loss decreases monotonically and that validation loss (2019) plateaus before early stopping.
3. Confirm hydrologic sanity by plotting:
   - Hourly hydrograph for 2020 (`modeling/plot_suite.py`).
   - Monthly RMSE improvements.
4. Archive the evaluation CSV, metrics JSON, and key plots into `local_only/results/<site>/2020_v2/`.

Metrics will be added to this document after each site completes the new evaluation cycle.
