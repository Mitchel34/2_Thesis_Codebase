# Transformer Residual-Correction Run (2010-2022)

## Overview
This document captures the completed data acquisition, preprocessing, and model training cycle for the Hydra temporal transformer that corrects National Water Model (NWM) streamflow forecasts at the Watauga study site. The run trains on 2010-2020, validates on 2021, and tests on 2022, establishing a baseline before iterating on new architectural experiments.

## Data Acquisition Summary
- **ERA5 meteorology**: `data_acquisition_scripts/era5.py` pulled enhanced ERA5 features for 2010–2023. Files reside under `data/raw/era5/19743430/` (monthly CSVs).
- **USGS observations**: `data_acquisition_scripts/usgs.py` downloaded daily discharge for gage 03479000 (2010–2022). Outputs are per-year CSVs plus `data/raw/usgs/03479000_consolidated.csv`.
- **NWM retrospective**:
  - v2.1 retrospective (2010–2020) captured via `data_acquisition_scripts/nwm.py` → `data/raw/nwm_v3/retrospective/nwm_v2p1_hourly_20100101_20201231.csv`.
  - v3.0 retrospective (2021–2022) harvested from the `noaa-nwm-retrospective-3-0-pds` bucket → `data/raw/nwm_v3/retrospective/nwm_v3_hourly_20210101_20221231.csv`.
- All acquisition scripts were instrumented with log files in `logs/` for replay and auditing (`era5_full.log`, `usgs_full.log`, `nwm_v2_full.log`, `nwm_v3_full.log`).

## Dataset Preparation
- Builder script: `modeling/build_training_dataset.py` ingested the raw feeds, merged on timestamp, derived residuals (`USGS - NWM`), and wrote the master parquet `data/clean/modeling/hourly_training_2010-01-01_2022-12-31.parquet` plus a sample CSV.
- Split files produced from the parquet:
  - `train_2010_2020.parquet` — 2010-01-01 to 2020-12-31 (training window).
  - `val_2021.parquet` — 2021-01-01 to 2021-12-31 (validation window).
  - `test_2022.parquet` — 2022-01-01 to 2022-12-31 (evaluation window).
- Dynamic features include NWM discharge and available ERA5 meteorological predictors; static context (e.g., NLCD fractions, regulation flag) is normalized using the training window statistics.

## Model & Training Configuration
- **Architecture file**: `modeling/models/hydra_temporal.py` (single-head causal transformer with residual & corrected heads).
- **Training script**: `modeling/train_quick_transformer_torch.py`.
- **Command**:
  ```bash
  PYTHONPATH=. python3.11 modeling/train_quick_transformer_torch.py \
    --data data/clean/modeling/hourly_training_2010-01-01_2022-12-31.parquet \
    --seq-len 168 --epochs 40 --batch-size 64 \
    --train-days 4018 --val-days 365 --patience 5 \
    --no-compile
  ```
- AMP kept enabled (bfloat16 on MPS); tensors exported to NumPy are cast back to float32 to avoid dtype incompatibilities.
- Optimizer: `AdamW` (lr 1e-3, weight decay 1e-4) with cosine annealing LR schedule, gradient clipping at 1.0, and consistency + bias penalties in the loss.

## Training Timeline
- Training loader spans the first 4,018 days (2010-01-01 to 2020-12-31).
- Validation monitors the 2021 block with patience=5; early stopping triggered after epoch 10.
- Final model checkpoint restored to the best validation loss before evaluation on the 2022 hold-out year.

## Evaluation Results (2022 Test Year)
| Metric | Baseline NWM | Corrected Model |
| --- | --- | --- |
| RMSE (cms) | 5.97 | **5.34** |
| MAE (cms) | 1.78 | **1.27** |
| NSE | 0.519 | **0.615** |
| KGE | **0.639** | 0.601 |
| PBIAS (%) | -5.99 | -9.00 |
| Pearson r | 0.723 | **0.796** |
| Spearman r | 0.832 | **0.922** |

- Residual RMSE (model vs. true residual) = 5.95 cms.
- RMSE improvement relative to baseline: **10.6 %**.
- Trade-off: corrected forecasts show stronger correlation and lower absolute error but slightly increased negative bias (underprediction).

Artifacts emitted by the run:
- `data/clean/modeling/quick_pred.npy` — residual predictions.
- `data/clean/modeling/quick_true.npy` — residual targets.
- `data/clean/modeling/quick_eval.csv` — timestamped evaluation records.
- `data/clean/modeling/quick_metrics.json` — serialized metric bundle.
- `data/clean/modeling/quick_features.txt` — dynamic/static feature roster used.
- Console log archived in `logs/train_full.log`.

## Next Steps
- Use this baseline documentation to benchmark architectural tweaks (e.g., attention refinements, hyperparameter search, alternative loss weighting).
- Investigate strategies to reduce the residual bias (e.g., bias-aware loss term, calibration layer).
- Develop automated evaluation scripts/plots (`modeling/plot_quick_eval.py`) to visualize errors and hydrologic behaviour across hydrologic events.
