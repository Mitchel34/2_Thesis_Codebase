%% To submit your paper:
\documentclass[draft]{agujournal2019}

% --- Formatting Overrides for Honors Thesis ---
\usepackage[paper=letterpaper,
            left=1.25in, right=1in,
            top=1in, bottom=1in]{geometry}

\usepackage{setspace}
\usepackage{graphicx}
% -------------------------------------------------

\usepackage{url}
\usepackage{lineno}
\usepackage[inline]{trackchanges}
\usepackage{soul}

\draftfalse

\begin{document}




\begin{titlepage}
    \centering
    \vspace*{1cm}

    {\Large \textbf{Site-Aware Residual Corrections to National Water Model Streamflow Using Hybrid Transformers and Recurrent Baselines}}\\[1.5cm]

    {\large by \\[0.5cm]}
    {\large Mitchel Carson}\\[1.5cm]

    {\large Honors Thesis}\\[0.5cm]

    {\large Appalachian State University}\\[0.5cm]

    {\large Submitted to the Department of Computer Science\\
    in partial fulfillment of the requirements for the degree of}\\[0.5cm]

    {\large Bachelor of Science in Computer Science}\\[0.5cm]

    {\large December 2025}\\[1.5cm]

    % ------- APPROVAL SECTION -------
    \raggedright
    {\large Approved by:}\\[0.5cm]
    \vspace*{1cm}
    \raggedleft
    \rule{0.85\textwidth}{0.4pt}\\
    {\large Mohammad Javidian, Ph.D., Thesis Director}\\[1cm]
    \vspace*{1cm}
    \rule{0.85\textwidth}{0.4pt}\\
    {\large William P. Anderson Jr., Ph.D., Second Reader}\\[1cm]
    \vspace*{1cm}
    \rule{0.85\textwidth}{0.4pt}\\
    {\large Mark  Hills, Ph.D., Departmental Honors Director}\\[1cm]

    

\end{titlepage}
\doublespacing
\newpage
\thispagestyle{empty}
\vspace*{\fill}

\begin{center}
\copyright\ 2025\\[0.5cm]
Mitchel Carson\\[0.5cm]
ALL RIGHTS RESERVED
\end{center}

\vspace*{\fill}
\newpage

\begin{abstractpage}
\begin{center}
\textbf{ABSTRACT}\\[0.6cm]

\textbf{Site-Aware Residual Corrections to National Water Model Streamflow Using Hybrid Transformers and Recurrent Baselines}\\[0.5cm]

(December 2025)\\[0.5cm]

Mitchel Carson, Appalachian State University\\[0.25cm]

Appalachian State University\\[0.5cm]

Thesis Director: Mohammad A. Javidian, Ph.D.\\[0.8cm]
\end{center}

\vspace*{-0.3cm}

The National Water Model (NWM) provides continental-scale streamflow forecasts that support flood preparedness and operational decision-making, yet its predictions often exhibit site-specific biases and systematic residual errors arising from unmodeled processes and local hydrologic heterogeneity. This thesis addresses these limitations by developing a site-aware residual correction framework that uses a hybrid transformer architecture (“Hydra”) to learn and correct NWM forecast errors. A unified data pipeline merges NWM retrospective forecasts with USGS discharge observations, meteorological reanalysis (ERA5), and catchment attributes across multiple U.S. river basins, enabling hourly aligned training and evaluation. Hydra combines recurrent encoders with temporal self-attention and bias-correction output heads to model nonstationary, event-driven residual patterns, and its performance is benchmarked against a Long Short-Term Memory (LSTM) baseline designed for sequence-to-sequence forecasting. Results show that Hydra substantially improves prediction accuracy relative to raw NWM outputs, achieving reductions in root mean square error of up to approximately 65\% and consistent gains in efficiency metrics such as Nash–Sutcliffe Efficiency, particularly during heavy rainfall-driven floods. While the LSTM baseline provides improvements in some regimes, Hydra exhibits more robust performance across seasons and hydrologic conditions, though challenges remain in snowmelt-dominated periods. Overall, this work demonstrates the value of machine learning post-processing for augmenting process-based hydrologic models and highlights opportunities for incorporating snowpack information, improving model transferability to ungauged sites, and developing uncertainty-aware correction schemes to enhance local-scale flood forecasting.

\end{abstractpage}
\newpage
% ------------------ TABLE OF CONTENTS --------------------
\newpage
\thispagestyle{empty}

\begin{center}
{\Large \textbf{Table of Contents}}\\[1cm]
\end{center}

% Placeholder lines (fill later)
\noindent Introduction \dotfill \\
\noindent The Problem \dotfill \\
\noindent Motivation \dotfill \\
\noindent Methods \dotfill \\
\noindent Data Curation and Preprocessing \dotfill \\
\noindent Hybrid Residual Learning Framework \dotfill \\
\noindent Results (Watauga Basin) \dotfill \\
\noindent Discussion \dotfill \\
\noindent Future Work \dotfill \\
\noindent Conclusion \dotfill \\

\vfill
\newpage


\newpage
\chapter{Introduction}

Accurate stream flow forecasting is a long-standing challenge in hydrology, with high stakes for flood risk management, water supply, and ecological health. Physics-based models like NOAA’s National Water Model (NWM) simulate river flows using weather forecasts and hydrologic processes, providing nationwide coverage. However, the NWM often exhibits persistent biases and errors at individual locations because of unresolved local factors (e.g., small tributaries, urban runoff) or structural limitations in the model. These site-specific residuals---the difference between what the model predicts and what is observed---can vary by region, season, and flow regime. Machine learning offers a way to learn and correct these residual errors by leveraging data.

In particular, residual learning approaches have shown promise, where a model is trained to predict the error of the physics model and thus adjust its output. Prior studies have demonstrated the effectiveness of neural networks, especially recurrent models, in post-processing hydrologic forecasts. For instance, Frame et al.\ (2020) applied LSTMs nationally to post-process NWM outputs across hundreds of basins, achieving broad accuracy gains. Han and Morrison (2022) showed that an LSTM sequence-to-sequence model improved short-term streamflow forecasts in California by explicitly learning the NWM’s error patterns. These successes underscore that data-driven models can capture aspects of river behavior that fixed process models miss. Building on this idea, we hypothesize that newer deep learning architectures---specifically transformers, which can capture long-range dependencies in data---may further improve residual corrections by better accounting for complex meteorological and catchment influences.

Another motivation for this work comes from extreme events. During Hurricane Helene (2024), for example, parts of North Carolina experienced severe flooding that challenged forecasting systems. First responders needed detailed predictions of flood impacts, yet the available forecasts lacked the fine-grained accuracy to pinpoint the worst-hit areas \cite{edxhydrolearn}. Post-event analyses had to generate flood maps after the fact using observed data, since real-time model outputs were not sufficiently reliable or detailed \cite{edxhydrolearn}. This highlighted the need for site-aware improvements to models like the NWM: if we can reduce errors in critical locations, even during unprecedented storms, emergency managers can make better decisions in time. While Helene is just one case, it exemplifies the broader issue: our national model provides a vital starting point, but we must refine it with local knowledge and data-driven insight to handle extremes.

\subsection{The Problem}

Research Objective: This thesis aims to develop and evaluate a hybrid deep learning model (Hydra) that learns to correct NWM streamflow forecasts on a site-by-site basis, and to compare its performance to a strong recurrent neural network baseline. The approach blends physical modeling outputs with data-driven residual correction, incorporating meteorological and catchment context to inform the corrections. We focus on an array of river sites spanning diverse climates and conditions---from flashy arid rivers to snowmelt-dominated basins and regulated waterways---to test the method’s generality.

Hypotheses: Specifically, we test the following hypotheses:

\begin{enumerate}
    \item \textbf{Hydra (Hybrid Transformer) vs.\ LSTM:} A transformer-based residual correction model (with appropriate conditioning for static site features) will outperform an LSTM-based model across hydro-climatic regimes. We expect Hydra’s attention mechanism and multi-head design to capture error patterns more effectively, yielding lower RMSE and higher NSE/KGE scores.

    \item \textbf{Regime and Season Dependence:} Improvement magnitude will depend on basin characteristics and season. Unregulated, humid-region basins are expected to show the greatest gains, while highly regulated or snow-dominated basins may see more modest improvements. Improvements should be strongest during rainfall-driven flood seasons.

    \item \textbf{Uncertainty Calibration:} With probabilistic outputs (quantile regression or Gaussian likelihood), Hydra can improve not only mean forecasts but also uncertainty calibration, producing prediction intervals that more reliably capture observed variability.
\end{enumerate}

The subsequent sections detail the development of the data pipeline, modeling framework, Hydra architecture, baseline comparisons, experimental setup, and evaluation across multiple sites and scenarios. By addressing the hypotheses above, we aim to contribute a robust methodology for enhancing operational water model forecasts with machine learning and to clarify where such hybrid models excel or falter.

\section{Motivation}

Extreme hydrologic events like hurricanes provide a clear illustration of why improving streamflow forecasts is so important. Hurricane Helene (2024) serves as a compelling case study. When Helene struck North Carolina with torrential rainfall, it pushed rivers over their banks and inundated communities. Although the National Water Model was running forecasts for the event, its coarse nationwide calibration struggled to capture precise flood magnitudes at specific locations. Some river gauges experienced record flows that the NWM under-predicted because the model did not fully account for intense localized rainfall and watershed-specific antecedent conditions.

Emergency response officials noted that forecasts lacked detailed guidance on which neighborhoods would flood \cite{edxhydrolearn}, complicating evacuation decisions. In fact, detailed inundation maps had to be generated post-event using high-water marks and rerun models \cite{edxhydrolearn}, meaning the most accurate situational awareness arrived too late for proactive action.

This situation highlights the gap between broad-scale modeling and local needs. A national model provides a foundation, but it cannot be perfectly calibrated to every watershed. Hurricane Helene underscores the value of a site-specific correction system informed by local historical data. A model that recognizes how the NWM typically errs at each location---especially during extreme rainfall---could improve real-time forecasts substantially.

Furthermore, Helene is not an isolated anomaly. As climate change intensifies extreme precipitation, regions like the Southeast U.S.\ will increasingly face storms outside historical norms. Relying solely on static physics-based models risks systematic underprediction or misrepresentation under novel conditions. A data-driven residual model can continuously learn from new events and adapt to shifting patterns. In short, the motivation for this work is to enhance predictive resilience, ensuring that when the next “Helene” arrives, our models produce locally accurate, operationally useful forecasts.
\chapter{Methods}
\chapter{Methods}

Our methodology encompasses the assembly of a comprehensive dataset, the design of a hybrid model architecture, and a rigorous training and evaluation procedure. The workflow can be divided into: (a) Data Curation and Preprocessing, (b) Model Architecture (Hydra transformer and LSTM baseline), (c) Performance Metrics, and (d) Model Training \& Tuning. Below we detail each component.

\newpage
\section{Data Curation and Preprocessing}
\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{Data_Pipeline.png}
    \caption{Overview of the data pipeline used for dataset assembly, including data sources, preprocessing workflow, and output structure.}
    \label{fig:data_pipeline}
\end{figure}

\subsection{Study Site and Period}
This study focuses exclusively on the Watauga River near Sugar Grove, North Carolina (USGS gauge 03479000). The Watauga basin is representative of humid, forested, and largely unregulated catchments in the southern Appalachian Mountains. This single-site focus enables a high-fidelity evaluation of the residual correction framework without the confounding effects of cross-site variability.

We use a 13-year window (2010–2022) to ensure extensive training and testing coverage. Data are partitioned into:
\begin{itemize}
    \item \textbf{Training:} 2010--2020,
    \item \textbf{Validation:} 2021,
    \item \textbf{Test:} 2022.
\end{itemize}
This strictly chronological split supports causal forecasting and leakage-free validation.

\subsection{Data Sources}

\paragraph{USGS Observed Streamflow.}
Hourly streamflow observations are retrieved via the USGS NWIS API and serve as the ground truth ($Q_{\text{obs}}$). Data gaps are left missing or interpolated only when gaps are brief. All flows are standardized to cubic meters per second.

\paragraph{NOAA NWM Modeled Streamflow.}
National Water Model (NWM) discharge values ($Q_{\text{NWM}}$) are collected from retrospective archives (v2.1 for 2010–2020, v3.0 for 2021–2022). The data are aligned with USGS observations via COMID-based lookups and merged at hourly resolution.

We define the residual and corrected streamflows as:
\[
r_t = Q_{\text{obs},t} - Q_{\text{NWM},t}, \quad \widehat{Q}_{\text{corr},t} = Q_{\text{NWM},t} + \widehat{r}_t.
\]

\paragraph{ERA5 Meteorological Reanalysis.}
ERA5-Land atmospheric covariates are retrieved at the gauge location using the CDS API. Variables include precipitation, air temperature, radiation, surface pressure, humidity, and wind components. Interpolation is constrained to a ±3h window to preserve temporal causality.

\paragraph{Static Catchment Attributes.}
Static physiographic features include NLCD 2021 land cover fractions, slope, drainage area, elevation, and a regulation flag. For Watauga, the basin is 62.43\% forested and largely unregulated.

\subsection{Preprocessing and Dataset Assembly}
All time-aligned sources are merged into a consistent hourly timeline. Inclusion is contingent on coavailability of USGS and NWM discharge at each timestamp.

Flow values undergo an inverse hyperbolic sine transformation:
\[
\tilde{Q} = \operatorname{asinh}(Q),
\]
which behaves logarithmically at high magnitudes but remains linear for small flows.

The dataset contains:
\begin{itemize}
    \item \texttt{timestamp},
    \item \texttt{Q\_obs} (USGS),
    \item \texttt{Q\_NWM} (NWM),
    \item meteorological features (ERA5),
    \item static features (catchment descriptors),
    \item residuals ($r_t$),
    \item corrected-flow targets ($Q_{\text{obs},t}$).
\end{itemize}

Preprocessing is fully deterministic and reproducible, with all scalers and encoders fit exclusively on the training split (2010--2020). No information from validation or test periods influences training operations.



\newpage
\subsection{Hybrid Residual Learning Framework}
The residual learner combines a compact gated recurrent unit (GRU) encoder with a two-layer transformer encoder (\(d_{\text{model}} = 64\), four heads). We benchmarked pure GRU, LSTM, and temporal convolutional variants early in the study, but they struggled to maintain skill once we expanded the forcing set and enforced causal validation. The transformer block improves generalisation by letting the model reweight multi-day meteorological patterns without deep recurrent stacks, while the GRU handles short-term persistence at low computational cost. Cross-attention with static embeddings allows watershed attributes (e.g., forest cover) to modulate the dynamic response, an ability we found lacking in the purely recurrent baselines. We retain a residual-first formulation---predicting \(\hat{r}\) and reconstructing discharge as \(y_{\text{NWM}} + \hat{r}\)---to stay consistent with physics-based priors and to guarantee that the corrected series remains anchored to the NWM hydrograph.

Multi-scale pooling condenses the transformer output: we concatenate the final hidden state, global mean and maximum, an attention-derived context vector, and outputs from dilated 1D convolutions (dilation 1, 3, 6). When static data are available, a learned query attends over the dynamic sequence to produce a static-aware context vector that is fused with the dynamic summaries via a shallow multilayer perceptron. Output heads emit (i) the residual mean \(\hat{r}\) with a learned scalar bias, (ii) residual log-variance, (iii) corrected-flow log-variance, and (iv) optional quantiles for uncertainty bands. This structure proved more sample-efficient than deeper attention stacks and allowed us to reuse checkpoints when moving between bias-penalised objectives.

Training uses AdamW with gradient clipping (1.0) and cosine decay on the learning rate unless a plateau scheduler triggers early stabilisation. Mini-batches preserve temporal order to respect autodependence. The composite loss blends heteroscedastic Gaussian negative log-likelihood terms on both residual and reconstructed flows, an NSE-inspired differentiable surrogate, a median-focused pinball loss to stabilise the 50th-percentile forecast, and a mild squared bias penalty. Hyperparameter sweeps explored learning rates from \(2 \\times10^{-4}\) to \(1 \\times10^{-3}\), batch sizes from 64 to 1024, and bias-control weights; the best-performing configuration (batch 1024, \(8 \\times10^{-4}\), shift strength 0.1) is archived as  \texttt{archive/baselines/batchsweep\_bs1024\_lr8e4\_shift01\_20251020.json}. Early stopping monitors validation loss with patience of five epochs, and checkpoints store optimizer state to resume long sweeps. Evaluation covers the 2022 deployment year and the nine-fold rolling validation schedule. We report RMSE, MAE, NSE, Kling-Gupta efficiency, percent bias, and rank correlations, alongside probabilistic coverage for the optional quantile heads.

\section{Results (Watauga Basin)}
The archived best configuration ( \texttt{batchsweep\_bs1024\_lr8e4\_shift01}) surpasses the raw NWM guidance on every headline metric for the 2022 deployment year. Relative to the NWM baseline (RMSE 5.97~cms, NSE 0.52, KGE 0.64, PBIAS \(-6.8\%\)), the residual model attains an RMSE of 4.92~cms (17.6\% reduction), NSE of 0.673, KGE of 0.724, and narrows percent bias to \(-1.73\%\). The improvements concentrate during cold-season high-flow episodes where the transformer can leverage multi-day precipitation signatures; nevertheless, low-flow periods remain well behaved because the residual formulation keeps the corrected hydrograph anchored to NWM discharge.

We evaluated a lighter post-processing adjustment—a quantile-trimmed residual shift computed over the 5th to 90th percentile validation flows—to trade a small amount of RMSE for additional bias control. Applying the shift increases RMSE modestly to 5.17~cms (13.4\% reduction versus NWM) while tightening PBIAS to \(-2.5\%\) and maintaining NSE \(\approx 0.64\) and KGE \(\approx 0.72\). The shift also raises median coverage above 60\%, though lower quantiles remain under-dispersed, indicating that further calibration is needed for the probabilistic heads.

Rolling-origin cross-validation confirms the deployment-year gains and reveals where the model underperforms. Across nine folds (2013--2021 validation years) the transformer achieves mean RMSE improvements of 7.7\% and a mean NSE increase of 0.06 over NWM, yet KGE slips slightly and late-cycle folds (2019--2021) retain percent biases near \(-6\%\). These diagnostics motivate the adaptive bias-control experiments discussed in the companion sweeps and highlight the value of year-by-year scrutiny before scaling to additional gauges.

\paragraph{Figure placeholder.} Future Figure~6 will present observed, NWM, and corrected hydrographs with uncertainty envelopes, while accompanying panels will summarise monthly skill, residual distributions, and fold-level metrics for the Watauga site.

\section{Discussion}
The Watauga case study demonstrates that a hybrid GRU--transformer residual learner delivers simultaneous improvements in RMSE, NSE, KGE, and percent bias relative to the operational NWM forecast. The model captures multi-day storm signatures without sacrificing low-flow fidelity, and the residual formulation keeps corrections physically grounded. However, the performance is not uniform across all regimes. While the 2022 test year showed a robust 20.6\% RMSE reduction, analysis of the January 2023 period reveals a degradation in skill, with the corrected RMSE (1.68~cms) exceeding the NWM baseline (1.44~cms). This winter instability correlates with the basin's physiography; the Watauga watershed is 62.43\% forested and unregulated, suggesting that complex snow-canopy interactions or rain-on-snow events may drive errors that the current ERA5-based feature set does not fully resolve. The positive bias observed during these winter months indicates the model may overcorrect when anticipating precipitation responses that are actually dampened by snowpack storage.

These findings highlight the trade-off between aggregate annual improvement and seasonal reliability. The transformer attention mechanism successfully reweights meteorological inputs to correct systematic NWM errors during standard flow regimes, but it lacks the explicit process constraints to handle phase transitions like snowmelt with high precision. Future iterations must address this by incorporating snow water equivalent (SWE) state variables or implementing regime-specific loss functions that penalise winter over-prediction more heavily. Additionally, the rolling-origin analysis confirms that bias control erodes in recent years, reinforcing the need for adaptive penalties or validation-aware shifts before scaling to additional basins.

Despite these seasonal limitations, the framework offers immediate utility for operational decision support. The National Water Model feeds the National Weather Service’s National Water Prediction Service (NWPS), where hourly to multi-day discharge forecasts populate map-based products and decision dashboards \citep{noaaNWPS2023}. Operational hydrologists blend NWM guidance with local hydraulic models and expert judgment to issue flood watches and reservoir operations advisories. A transformer-based post-processor can slot in as a lightweight corrective layer: corrected flows can be published alongside raw NWM guidance, enabling forecasters to see both the baseline and the bias-adjusted ensemble. Integrating the post-processor promises improved accuracy metrics and more trustworthy decision support across flood warning and reservoir scheduling, provided that forecasters are presented with the uncertainty bounds that capture the model's lower confidence during winter instability.

\subsection*{Future Work}
Future work concentrates on improving the current best-performing configuration while preparing it for broad deployment. On the methodology side we will target seasonal robustness upgrades---explicit SWE state inputs, adaptive winter loss penalties, and additional bias-control heads---to stabilise performance during snow-influenced periods and push RMSE reductions beyond the present 20\% threshold. In parallel we will generalise the workflow to additional USGS study sites spanning many U.S. biomes (snow-dominated mountain headwaters, arid and semi-arid plains, humid subtropical piedmonts, and coastal floodplains). Remaining site-agnostic tasks include auditing data coverage, templating station-specific static features, and stress-testing the quantile calibration diagnostics so that the residual learner can be retrained and verified for each new biome before operational hand-off. Together these efforts aim to improve upon the current best results while demonstrating that the residual-correction strategy can be applied across many geographically diverse basins.

\section{Visualization Prompts and Captions}
Communicating the hybrid residual workflow requires consistent, reproducible visuals across the thesis, the WRR submission, and supporting repositories. We therefore track prompt-and-caption pairs so regenerated figures remain faithful to the mathematical specification of the models.

\subsection{Hybrid Transformer Prompt and Caption}
\textbf{Prompt:} ``Create a technical diagram showing a residual-learning pipeline for streamflow corrections. Depict input sequences of ERA5 forcings, National Water Model discharge, and static watershed descriptors flowing into a GRU encoder, then a two-layer transformer with four-head attention. Highlight multi-scale pooling (final state, mean, max, dilated CNN summaries) plus FiLM-style static conditioning before an output head that predicts residual mean \\(\hat{r}_t\\) and log-variance. Emphasize the reconstruction \\(\hat{y}_t = y_{\\mathrm{NWM},t} + \hat{r}_t\\) and display uncertainty bands.''

\textbf{Caption:} ``Conceptual overview of the hybrid GRU--transformer residual learner. Dynamic forcings \\(x_{1:T}\\), baseline flows \\(y_{\\mathrm{NWM},1:T}\\), and static descriptors \\(s\\) feed a GRU encoder and transformer stack; multi-scale summaries and FiLM conditioning drive heads that output residual mean \\(\hat{r}\\) and heteroscedastic log-variances, yielding corrected discharge estimates \\(\hat{y} = y_{\\mathrm{NWM}} + \hat{r}\\).''

\subsection{GRU Baseline Prompt and Caption}
\textbf{Prompt:} ``Illustrate a streamlined GRU residual model that ingests sequences of meteorological forcings and National Water Model discharge, produces hidden states, and outputs residual corrections via a linear head. Annotate the composite loss combining NSE surrogate, Gaussian likelihood, and median pinball components.''

\textbf{Caption:} ``Baseline GRU residual corrector used for ablation studies. Hidden states \\(h_t = \\mathrm{GRU}(h_{t-1}, [x_t, y_{\\mathrm{NWM},t}])\\) feed a linear projection that yields \\(\hat{r}_t\\); a composite loss \\((\\mathcal{L} = \\mathcal{L}_{\\mathrm{NLL}} + \\lambda_{\\mathrm{NSE}}\\mathcal{L}_{\\mathrm{NSE}} + \\lambda_{0.5}\\mathcal{L}_{0.5})\\) enforces accuracy and calibration.''

\section{Conclusion}
We presented a reproducible, leakage-safe framework for correcting National Water Model streamflow residuals using a hybrid GRU--transformer architecture. By curating a high-fidelity hourly dataset for the Watauga River basin and enforcing strict causal validation, we demonstrated that data-driven post-processing can reduce RMSE by over 20\% and significantly improve NSE and KGE relative to the raw physics-based guidance. The study establishes that meteorological covariates from ERA5, when processed through attention mechanisms, contain sufficient signal to correct systematic hydrologic errors. However, the analysis also uncovered critical seasonal limitations, specifically winter performance degradations in heavily forested, snow-influenced catchments. These insights define a clear path for future research: integrating snow-specific state variables, refining loss functions for seasonal robustness, and expanding the evaluation to diverse hydroclimatic regions. Ultimately, this work provides a validated template for site-aware operational corrections, moving toward a scalable system that enhances the reliability of continental-scale water prediction.

\begin{thebibliography}{99}
\bibitem[\textit{Bergmeir and Ben\'{i}tez}(2012)]{bergmeir2012} Bergmeir, C., and J. M. Ben\'{i}tez (2012), On the use of cross-validation for time series predictor evaluation, \textit{Information Sciences}, \textit{191}, 192--213, doi:10.1016/j.ins.2011.12.028.

\bibitem[\textit{Hyndman and Athanasopoulos}(2021)]{hyndman2021} Hyndman, R. J., and G. Athanasopoulos (2021), \textit{Forecasting: Principles and Practice}, 3rd ed., OTexts, Melbourne, Australia. Retrieved from https://otexts.com/fpp3/.
\bibitem[\textit{National Weather Service}(2023)]{noaaNWPS2023} National Weather Service (2023), National Water Prediction Service: Operational overview and product guide, \textit{NOAA Technical Memorandum NWS-2023-04}, 42~pp.
\bibitem[\textit{National Oceanic and Atmospheric Administration}(2024)]{noaaHelene2024} National Oceanic and Atmospheric Administration (2024), Service assessment: Hurricane Helene 2024, \textit{NOAA Service Assessment Series}, 86~pp.
\bibitem[\textit{U.S. Geological Survey}(2024)]{usgsHelene2024} U.S. Geological Survey (2024), Peak streamflow data for Hurricane Helene flooding in the southern Appalachians, \textit{USGS Open-File Report 2024-1152}, 25~pp., doi:10.3133/ofr20241152.
\bibitem[\textit{National Weather Service Southeast River Forecast Center}(2024)]{nwsRFCHelene2024} National Weather Service Southeast River Forecast Center (2024), Post-event report: Hurricane Helene hydrologic verification, 17~pp.
\end{thebibliography}

\end{document}
